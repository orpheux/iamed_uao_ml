"""
ğŸ¯ SERVICIO DE ENTRENAMIENTO PARA HOMOLOGACIÃ“N DE MEDICAMENTOS
============================================================
Servicio basado EXACTAMENTE en p04_training.ipynb con KMeans completo.
Flujo: parquet â†’ KMeans + clustering â†’ modelo.pkl

Author: Sistema IAMED
Version: 1.0.0
"""

import os
import pickle
import warnings
from typing import Tuple, Optional

import polars as pl
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.neighbors import NearestNeighbors
warnings.filterwarnings('ignore')


class HomologacionClusteringModel:
    """
    Modelo de clustering especializado para homologaciÃ³n de medicamentos.
    BASADO EXACTAMENTE EN p04_training.ipynb

    Estrategia:
    1. Clustering primario por ATC+VÃA (variables crÃ­ticas)
    2. Clustering secundario por caracterÃ­sticas especÃ­ficas con KMEANS
    3. Sistema de similitud con pesos jerÃ¡rquicos
    """

    def __init__(self, pesos_jerarquicos: Optional[dict] = None):
        """Inicializa el modelo de clustering para homologaciÃ³n."""
        self.pesos_jerarquicos = pesos_jerarquicos or {
            'ATC': 0.40,                    # 40% - CRÃTICO
            'VIA_ADMINISTRACION': 0.30,     # 30% - CRÃTICO
            'FORMA_FARMACEUTICA': 0.20,     # 20% - IMPORTANTE
            'CANTIDAD_SIMILITUD': 0.10,     # 10% - IMPORTANTE
            'PRINCIPIO_BONUS': 0.00         # 0% base + bonus variable
        }

        # Modelos de clustering
        self.cluster_primario = None
        self.cluster_secundario = None
        self.scaler = StandardScaler()
        self.knn_model = None

        # Datos de entrenamiento
        self.df_validos = None
        self.df_referencia = None
        self.features_clustering = None
        self.datos_escalados = None

        # Mapeos y vocabularios
        self.combo_clusters = {}
        self.cluster_info = {}

    def preparar_features_clustering(self, df: pl.DataFrame) -> tuple:
        """Prepara las features optimizadas para clustering de homologaciÃ³n."""
        # FEATURES CRÃTICAS (deben coincidir exactamente para homologaciÃ³n)
        features_criticas = [
            'ATC_label',
            'VÃA ADMINISTRACIÃ“N_label',
            'PRINCIPIO ACTIVO_label'
        ]

        # FEATURES IMPORTANTES (permiten variaciÃ³n con penalizaciÃ³n)
        features_importantes = [
            'FORMA FARMACÃ‰UTICA_label',
            'CANTIDAD_log',
            'CANTIDAD_CUM_log',
            'RATIO_CANTIDAD',
            'CANTIDAD_bin',
            'UNIDAD MEDIDA_label'
        ]

        # FEATURES DE PROBABILIDAD (para scoring)
        features_probabilidad = [
            'ATC_prob_validos',
            'VÃA ADMINISTRACIÃ“N_prob_validos',
            'PRINCIPIO ACTIVO_prob_validos',
            'score_prob_critica'
        ]

        # Verificar disponibilidad
        features_criticas_disp = [
            f for f in features_criticas if f in df.columns]
        features_importantes_disp = [
            f for f in features_importantes if f in df.columns]
        features_prob_disp = [
            f for f in features_probabilidad if f in df.columns]

        # Combinar todas las features
        todas_features = features_criticas_disp + \
            features_importantes_disp + features_prob_disp

        return features_criticas_disp, features_importantes_disp, todas_features

    def clustering_por_combo_critico(self, df_validos: pl.DataFrame) -> tuple:
        """Realiza clustering primario agrupando por combinaciones crÃ­ticas ATC+VÃA."""
        # Analizar combinaciones ATC+VÃA
        combos_info = (df_validos
                       .group_by('ATC_VIA_combo')
                       .agg([
                           pl.len().alias('count'),
                           pl.col('ATC').first().alias('ATC_ejemplo'),
                           pl.col('VÃA ADMINISTRACIÃ“N').first().alias(
                               'VIA_ejemplo'),
                           pl.col('PRINCIPIO ACTIVO').n_unique().alias(
                               'principios_unicos')
                       ])
                       .sort('count', descending=True))

        # Asignar cluster_id a cada combinaciÃ³n
        combo_clusters = {}
        cluster_info = {}

        for idx in range(combos_info.height):
            row = combos_info.row(idx)
            combo = row[0]
            count = row[1]
            atc = row[2]
            via = row[3]
            principios = row[4]

            combo_clusters[combo] = idx
            cluster_info[idx] = {
                'combo': combo,
                'count': count,
                'atc': atc,
                'via': via,
                'principios_unicos': principios,
                'cluster_id': idx
            }

        return combo_clusters, cluster_info

    def clustering_secundario_por_similitud(self, df_validos: pl.DataFrame, features_importantes: list) -> None:
        """Aplica clustering secundario dentro de cada grupo ATC+VÃA con KMEANS."""
        # Preparar datos para clustering secundario
        features_disponibles = [
            f for f in features_importantes if f in df_validos.columns]

        # Extraer datos numÃ©ricos para clustering (convertir a numpy para sklearn)
        datos_clustering = df_validos.select(features_disponibles).to_numpy()

        # Escalar datos
        datos_escalados = self.scaler.fit_transform(datos_clustering)

        # Determinar nÃºmero Ã³ptimo de clusters usando mÃ©todo del codo
        # MÃ¡ximo 50 clusters o 1 cada 10 medicamentos
        max_k = min(50, len(datos_escalados) // 10)

        if max_k >= 2:
            # Probar diferentes valores de k
            inertias = []
            # Limitar a mÃ¡ximo 20 para eficiencia
            k_range = range(2, min(max_k + 1, 21))

            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(datos_escalados)
                inertias.append(kmeans.inertia_)

            # Elegir k usando mÃ©todo del codo simplificado
            if len(inertias) > 2:
                # Calcular second differences para encontrar el "codo"
                diffs = np.diff(inertias)
                second_diffs = np.diff(diffs)
                k_optimo = k_range[np.argmin(second_diffs) + 1]
            else:
                k_optimo = k_range[0]

            # Entrenar modelo final KMEANS
            self.cluster_secundario = KMeans(
                n_clusters=k_optimo, random_state=42, n_init=10)
            clusters_secundarios = self.cluster_secundario.fit_predict(
                datos_escalados)

            # Evaluar calidad si hay suficientes datos
            if len(datos_escalados) > k_optimo:
                _ = silhouette_score(datos_escalados, clusters_secundarios)

        else:
            clusters_secundarios = np.zeros(len(datos_escalados))
            k_optimo = 1

        # Entrenar modelo KNN para bÃºsqueda de similares
        self.knn_model = NearestNeighbors(n_neighbors=min(
            20, len(datos_escalados)), metric='cosine')
        self.knn_model.fit(datos_escalados)

        # Guardar datos para uso posterior
        self.datos_escalados = datos_escalados
        self.features_clustering = features_disponibles

    def fit(self, df_training: pl.DataFrame) -> None:
        """Entrena el modelo completo de clustering para homologaciÃ³n."""
        # Filtrar solo medicamentos vÃ¡lidos para entrenamiento
        self.df_validos = df_training.filter(pl.col('VALIDO') == 1)

        # Preparar features
        _, features_importantes, _ = self.preparar_features_clustering(self.df_validos)

        # Clustering primario por combinaciones crÃ­ticas
        self.combo_clusters, self.cluster_info = self.clustering_por_combo_critico(self.df_validos)

        # Clustering secundario por similitud con KMEANS
        self.clustering_secundario_por_similitud(self.df_validos, features_importantes)

        # Guardar dataset de referencia (todos los datos para bÃºsqueda)
        self.df_referencia = df_training

    def obtener_info_medicamento(self, cum: str) -> Optional[dict]:
        """Obtiene informaciÃ³n completa de un medicamento por su CUM."""
        if self.df_referencia is None:
            return None

        medicamento = self.df_referencia.filter(pl.col('CUM') == cum)

        if medicamento.height == 0:
            return None

        # Convertir a diccionario
        info = medicamento.to_pandas().iloc[0].to_dict()
        return info


class SistemaRecomendacionHomologos:
    """Sistema completo de recomendaciÃ³n de medicamentos homÃ³logos basado en p04_training."""

    def __init__(self, modelo_clustering: HomologacionClusteringModel):
        """Inicializa el sistema de recomendaciÃ³n."""
        self.modelo = modelo_clustering
        self.pesos = modelo_clustering.pesos_jerarquicos

    def calcular_score_similitud(self, medicamento_origen: dict, medicamento_candidato: dict) -> Tuple[float, dict]:
        """Calcula score de similitud entre medicamento origen y candidato."""
        detalle = {}
        score_total = 0.0

        # 1. ATC (40% - CRÃTICO)
        if medicamento_origen['ATC'] == medicamento_candidato['ATC']:
            score_atc = 1.0
            detalle['ATC'] = {'coincide': True,'score': 1.0, 'peso': self.pesos['ATC']}
        else:
            score_atc = 0.0
            detalle['ATC'] = {'coincide': False,'score': 0.0, 'peso': self.pesos['ATC']}

        score_total += score_atc * self.pesos['ATC']

        # 2. VÃA ADMINISTRACIÃ“N (30% - CRÃTICO)
        if medicamento_origen['VÃA ADMINISTRACIÃ“N'] == medicamento_candidato['VÃA ADMINISTRACIÃ“N']:
            score_via = 1.0
            detalle['VIA'] = {'coincide': True, 'score': 1.0,'peso': self.pesos['VIA_ADMINISTRACION']}
        else:
            score_via = 0.0
            detalle['VIA'] = {'coincide': False, 'score': 0.0,'peso': self.pesos['VIA_ADMINISTRACION']}

        score_total += score_via * self.pesos['VIA_ADMINISTRACION']

        # 3. PRINCIPIO ACTIVO (BONUS - MÃS FLEXIBLE)
        if medicamento_origen['PRINCIPIO ACTIVO'] == medicamento_candidato['PRINCIPIO ACTIVO']:
            bonus_principio = 0.15  # 15% bonus si coincide exactamente
            detalle['PRINCIPIO_BONUS'] = {'bonus': 0.15, 'tipo': 'exacto'}
        elif any(palabra in medicamento_candidato['PRINCIPIO ACTIVO'] for palabra in medicamento_origen['PRINCIPIO ACTIVO'].split() if len(palabra) > 3):
            bonus_principio = 0.10  # 10% bonus si coincide parcialmente
            detalle['PRINCIPIO_BONUS'] = {'bonus': 0.10, 'tipo': 'parcial'}
        else:
            bonus_principio = 0.0   # Sin bonus pero NO penaliza
            detalle['PRINCIPIO_BONUS'] = {'bonus': 0.0, 'tipo': 'diferente'}

        score_total += bonus_principio  # Se suma ENCIMA del 100%

        # 4. FORMA FARMACÃ‰UTICA (20% - IMPORTANTE)
        if medicamento_origen['FORMA FARMACÃ‰UTICA'] == medicamento_candidato['FORMA FARMACÃ‰UTICA']:
            score_forma = 1.0
            detalle['FORMA'] = {'coincide': True, 'score': 1.0,
                                'peso': self.pesos['FORMA_FARMACEUTICA']}
        else:
            score_forma = 0.5  # PenalizaciÃ³n menor para forma farmacÃ©utica
            detalle['FORMA'] = {'coincide': False, 'score': 0.5,
                                'peso': self.pesos['FORMA_FARMACEUTICA']}

        score_total += score_forma * self.pesos['FORMA_FARMACEUTICA']

        # 5. SIMILITUD DE CANTIDAD (10% - IMPORTANTE)
        cantidad_origen = medicamento_origen.get('CANTIDAD', 0)
        cantidad_candidato = medicamento_candidato.get('CANTIDAD', 0)

        if cantidad_origen > 0 and cantidad_candidato > 0:
            ratio = min(cantidad_origen, cantidad_candidato) / \
                max(cantidad_origen, cantidad_candidato)
            if ratio < 0.5:
                score_cantidad = 0.1
            elif ratio < 0.8:
                score_cantidad = 0.4
            else:
                score_cantidad = ratio
        else:
            score_cantidad = 0.3

        detalle['CANTIDAD'] = {
            'origen': cantidad_origen,
            'candidato': cantidad_candidato,
            'score': score_cantidad,
            'peso': self.pesos['CANTIDAD_SIMILITUD']
        }

        score_total += score_cantidad * self.pesos['CANTIDAD_SIMILITUD']

        return score_total, detalle

    def recomendar_homologos(self, cum_origen: str, n_recomendaciones: int = 5, score_minimo: float = 0.85) -> dict:
        """Encuentra medicamentos homÃ³logos para un CUM dado."""
        # 1. Obtener informaciÃ³n del medicamento origen
        medicamento_origen = self.modelo.obtener_info_medicamento(cum_origen)

        if medicamento_origen is None:
            return {
                'cum_origen': cum_origen,
                'encontrado': False,
                'error': 'CUM no encontrado en el dataset',
                'recomendaciones': []
            }

        # 2. Verificar si tiene combinaciÃ³n ATC+VÃA vÃ¡lida
        combo_origen = f"{medicamento_origen['ATC_label']}_{medicamento_origen['VÃA ADMINISTRACIÃ“N_label']}"

        if combo_origen not in self.modelo.combo_clusters:
            return {
                'cum_origen': cum_origen,
                'encontrado': False,
                'error': f'No hay medicamentos vÃ¡lidos con la combinaciÃ³n ATC+VÃA: {medicamento_origen["ATC"]} + {medicamento_origen["VÃA ADMINISTRACIÃ“N"]}',
                'recomendaciones': []
            }

        # 3. Buscar candidatos con la misma combinaciÃ³n ATC+VÃA
        if self.modelo.df_validos is None:
            return {
                'cum_origen': cum_origen,
                'encontrado': False,
                'error': 'Modelo no entrenado',
                'recomendaciones': []
            }

        candidatos = (self.modelo.df_validos
                      .filter(
                          (pl.col('ATC') == medicamento_origen['ATC']) &
                          (pl.col('VÃA ADMINISTRACIÃ“N') == medicamento_origen['VÃA ADMINISTRACIÃ“N']) &
                          # Excluir el medicamento origen
                          (pl.col('CUM') != cum_origen)
                      ))

        if candidatos.height == 0:
            return {
                'cum_origen': cum_origen,
                'encontrado': False,
                'error': f'No hay otros medicamentos vÃ¡lidos con ATC: {medicamento_origen["ATC"]}, VÃA: {medicamento_origen["VÃA ADMINISTRACIÃ“N"]}',
                'recomendaciones': []
            }

        # 4. Calcular scores de similitud para cada candidato
        recomendaciones = []

        for idx in range(candidatos.height):
            candidato = candidatos.row(idx, named=True)
            candidato_dict = dict(candidato)

            # Calcular score
            score, _ = self.calcular_score_similitud(medicamento_origen, candidato_dict)

            # Solo incluir si supera el score mÃ­nimo
            if score >= score_minimo:
                recomendaciones.append({
                    'cum': candidato_dict['CUM'],
                    'producto': candidato_dict['PRODUCTO'],
                    'atc': candidato_dict['ATC'],
                    'via': candidato_dict['VÃA ADMINISTRACIÃ“N'],
                    'principio_activo': candidato_dict['PRINCIPIO ACTIVO'],
                    'forma_farmaceutica': candidato_dict['FORMA FARMACÃ‰UTICA'],
                    'cantidad': candidato_dict['CANTIDAD'],
                    'unidad': candidato_dict['UNIDAD MEDIDA'],
                    'score_similitud': round(score, 4)
                })

        # 5. Ordenar por score y limitar nÃºmero
        recomendaciones.sort(key=lambda x: x['score_similitud'], reverse=True)
        recomendaciones = recomendaciones[:n_recomendaciones]

        return {
            'cum_origen': cum_origen,
            'medicamento_origen': {
                'producto': medicamento_origen['PRODUCTO'],
                'atc': medicamento_origen['ATC'],
                'via': medicamento_origen['VÃA ADMINISTRACIÃ“N'],
                'principio_activo': medicamento_origen['PRINCIPIO ACTIVO'],
                'es_valido': medicamento_origen['VALIDO'] == 1
            },
            'encontrado': len(recomendaciones) > 0,
            'candidatos_evaluados': candidatos.height,
            'recomendaciones': recomendaciones,
            'parametros': {
                'score_minimo': score_minimo,
                'n_recomendaciones': n_recomendaciones
            }
        }


class TrainingService:
    """
    Servicio principal para entrenar el modelo completo de homologaciÃ³n.
    BASADO 100% EN p04_training.ipynb
    """

    def __init__(self):
        self.modelo_clustering = None
        self.sistema_recomendacion = None

    def entrenar_modelo_completo(self, df_training: pl.DataFrame) -> dict:
        """Entrena el modelo completo (clustering + sistema de recomendaciÃ³n)."""
        print("ğŸš€ INICIANDO ENTRENAMIENTO DEL MODELO DE CLUSTERING")
        print("=" * 70)

        # 1. Entrenar modelo de clustering con KMEANS
        print("ğŸ¯ Paso 1: Entrenando modelo de clustering...")
        self.modelo_clustering = HomologacionClusteringModel()
        self.modelo_clustering.fit(df_training)
        print("âœ… Modelo de clustering entrenado exitosamente")

        # 2. Crear sistema de recomendaciÃ³n
        print("ğŸ¯ Paso 2: Creando sistema de recomendaciÃ³n...")
        self.sistema_recomendacion = SistemaRecomendacionHomologos(
            self.modelo_clustering)
        print("âœ… Sistema de recomendaciÃ³n creado")

        # 3. Crear modelo completo
        print("ğŸ¯ Paso 3: Empaquetando modelo completo...")
        modelo_completo = {
            'modelo_clustering': self.modelo_clustering,
            'sistema_recomendacion': self.sistema_recomendacion,
            'timestamp': pd.Timestamp.now(),
            'descripcion': 'Sistema completo de homologaciÃ³n de medicamentos con clustering jerÃ¡rquico',
            'version': '1.0.0',
            'stats': {
                'medicamentos_validos': self.modelo_clustering.df_validos.height if self.modelo_clustering.df_validos is not None else 0,
                'clusters_primarios': len(self.modelo_clustering.combo_clusters)
            }
        }

        print("âœ… Modelo completo creado:")
        print(
            f"   ğŸ“Š Medicamentos vÃ¡lidos: {modelo_completo['stats']['medicamentos_validos']:,}")
        print(
            f"   ğŸ¯ Clusters primarios: {modelo_completo['stats']['clusters_primarios']:,}")

        return modelo_completo

    def guardar_modelo(self, modelo_completo: dict, output_path: str) -> None:
        """Guarda el modelo entrenado en formato pickle."""
        print("ğŸ’¾ GUARDANDO MODELO ENTRENADO")
        print("=" * 40)

        # Crear directorio si no existe
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        print(f"ğŸ“ Directorio: {os.path.dirname(output_path)}")
        print(f"ğŸ“‚ Archivo: {os.path.basename(output_path)}")

        # Guardar usando pickle
        with open(output_path, 'wb') as f:
            pickle.dump(modelo_completo, f)

        # Verificar que se guardÃ³ correctamente
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024*1024)  # MB
            print("âœ… Modelo guardado exitosamente!")
            print(f"ğŸ“Š TamaÃ±o del archivo: {file_size:.2f} MB")
            print(f"ğŸ“ Ruta completa: {os.path.abspath(output_path)}")
        else:
            print("âŒ ERROR: El modelo no se guardÃ³ correctamente")
            raise RuntimeError(
                f"No se pudo guardar el modelo en: {output_path}")

    def cargar_modelo(self, model_path: str) -> dict:
        """Carga un modelo previamente entrenado."""
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"El modelo no existe en la ruta: {model_path}")

        with open(model_path, 'rb') as f:
            modelo_completo = pickle.load(f)

        return modelo_completo

    def entrenar_desde_archivo(self, input_path: str, output_path: str) -> dict:
        """Entrena modelo completo desde archivo."""
        print("ğŸ¯ INICIANDO ENTRENAMIENTO DESDE ARCHIVO")
        print("=" * 50)
        print(f"ğŸ“¥ Archivo de entrada: {input_path}")
        print(f"ğŸ“¤ Archivo de salida: {output_path}")

        if not os.path.exists(input_path):
            raise FileNotFoundError(f"No se encontrÃ³ el archivo: {input_path}")

        # Cargar dataset
        print("ğŸ“Š Cargando dataset de entrenamiento...")
        df_training = pl.read_parquet(input_path)
        print(
            f"âœ… Dataset cargado: {df_training.height:,} registros, {df_training.width} columnas")

        # Entrenar modelo completo
        modelo_completo = self.entrenar_modelo_completo(df_training)

        # Guardar modelo
        self.guardar_modelo(modelo_completo, output_path)

        print("\nğŸ‰ PROCESO COMPLETADO EXITOSAMENTE!")
        print("="*50)

        return modelo_completo


# Funciones utilitarias para uso directo
def entrenar_modelo_homologacion(input_path: str, output_path: str) -> dict:
    """
    FunciÃ³n directa: lee parquet, entrena con KMEANS, guarda pkl.
    BASADA EN p04_training.ipynb
    """
    service = TrainingService()
    return service.entrenar_desde_archivo(input_path, output_path)


def cargar_modelo_homologacion(model_path: str) -> dict:
    """Carga modelo entrenado para hacer bÃºsquedas."""
    service = TrainingService()
    return service.cargar_modelo(model_path)


def buscar_homologos(modelo_completo: dict, cum: str, n_recomendaciones: int = 5) -> dict:
    """Busca homÃ³logos usando modelo cargado."""
    sistema = modelo_completo['sistema_recomendacion']
    return sistema.recomendar_homologos(cum, n_recomendaciones)


if __name__ == "__main__":
    # Ejemplo de uso basado en p04_training
    INPUT_FILE = "./data/dataset_entrenamiento_homologacion.parquet"
    OUTPUT_FILE = "./models/iamed.pkl"

    print("ğŸ¯ EJEMPLO DE ENTRENAMIENTO COMPLETO")
    print("=" * 50)

    try:
        # Entrenar modelo con KMEANS
        print("ğŸš€ Iniciando entrenamiento...")
        modelo = entrenar_modelo_homologacion(INPUT_FILE, OUTPUT_FILE)
        print("âœ… Modelo entrenado exitosamente!")
        print(f"ğŸ“Š Stats: {modelo['stats']}")

        # Probar bÃºsqueda
        print("\nğŸ” Probando bÃºsqueda de homÃ³logos...")
        resultado = buscar_homologos(modelo, "2203-1", 3)
        print(f"âœ… HomÃ³logos encontrados: {len(resultado['recomendaciones'])}")

        for i, rec in enumerate(resultado['recomendaciones'], 1):
            print(
                f"   {i}. {rec['producto']} (Score: {rec['score_similitud']:.1%})")

    except FileNotFoundError as e:
        print(f"âŒ Error: {e}")
        print("ğŸ’¡ AsegÃºrate de que el archivo de datos existe en la ruta especificada")
    except Exception as e:
        print(f"âŒ Error inesperado: {e}")
        print("ğŸ’¡ Revisa que todos los datos y dependencias estÃ©n disponibles")
