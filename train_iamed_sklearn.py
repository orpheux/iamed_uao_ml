# =============================================================================
# SISTEMA DE HOMOLOGACI√ìN AUTOM√ÅTICA DE MEDICAMENTOS - SKLEARN DIRECTO
# =============================================================================
# Objetivo: Clustering eficiente con sklearn usando dataset encodificado
# Dataset: 248,635 medicamentos √ó 173 caracter√≠sticas encodificadas
# Estrategia: Sklearn puro + m√©tricas + sistema de recomendaci√≥n Top 5
# =============================================================================

# %%
# =============================================================================
# PASO 1: CONFIGURACI√ìN INICIAL E IMPORTS
# =============================================================================

from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score,
    silhouette_samples
)
from sklearn.cluster import (
    KMeans,
    DBSCAN,
    AgglomerativeClustering,
    Birch,
    MiniBatchKMeans
)
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import time
import logging
from datetime import datetime

warnings.filterwarnings('ignore')

# Sklearn imports para clustering

# M√©tricas de evaluaci√≥n

# An√°lisis y visualizaci√≥n

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('clustering_sklearn_medicamentos.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

print("üî¨ SISTEMA DE HOMOLOGACI√ìN AUTOM√ÅTICA DE MEDICAMENTOS - SKLEARN DIRECTO")
print("="*80)
print("üìä Objetivo: Clustering eficiente para recomendaci√≥n de medicamentos")
print("üéØ Estrategia: Sklearn puro + dataset encodificado optimizado")
print("üîù Output: Top 5 medicamentos similares por CUM inv√°lido")
print("‚ö° Ventaja: Sin overhead de PyCaret, m√°ximo control y eficiencia")
print("="*80)

# %%
# =============================================================================
# PASO 2: CARGA Y VERIFICACI√ìN DEL DATASET ENCODIFICADO
# =============================================================================

logger.info("Cargando dataset encodificado...")

# Ruta del dataset preparado
path_encoded = Path("./data/medicamentos_train_preprocesados.parquet")

# Verificar que existe
if not path_encoded.exists():
    raise FileNotFoundError(f"No se encontr√≥ el dataset: {path_encoded}")

# Cargar dataset
start_time = time.time()
df_encoded = pd.read_parquet(path_encoded)
load_time = time.time() - start_time

print(f"üìÅ Dataset cargado exitosamente en {load_time:.2f} segundos")
print(f"üìä Shape: {df_encoded.shape}")
print(
    f"üíæ Memoria: {df_encoded.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
print()

# Informaci√≥n b√°sica del dataset
logger.info(f"Dataset shape: {df_encoded.shape}")
logger.info(
    f"Memoria utilizada: {df_encoded.memory_usage(deep=True).sum() / 1024**2:.1f} MB")

# Verificar tipos de datos
print("üîç INFORMACI√ìN DEL DATASET:")
print(f"   - Columnas: {df_encoded.shape[1]}")
print(f"   - Tipos de datos: {df_encoded.dtypes.value_counts().to_dict()}")
print(f"   - Valores nulos: {df_encoded.isnull().sum().sum()}")
print(f"   - Primeras columnas: {list(df_encoded.columns[:10])}")

# %%
# =============================================================================
# PASO 3: IDENTIFICACI√ìN DE MEDICAMENTOS V√ÅLIDOS E INV√ÅLIDOS
# =============================================================================

print("\nüéØ IDENTIFICACI√ìN DE MEDICAMENTOS V√ÅLIDOS E INV√ÅLIDOS")
print("="*55)

# Buscar columnas de validez en el dataset encodificado
# Estas deber√≠an estar encodificadas como binarias (0/1)

# Buscar columnas relacionadas con estado/validez
validez_cols = []
for col in df_encoded.columns:
    col_lower = col.lower()
    if any(term in col_lower for term in ['estado', 'muestra', 'vigente', 'activo']):
        validez_cols.append(col)

print(f"üîç Columnas de validez encontradas: {validez_cols}")

# Si tenemos las columnas de validez encodificadas, crear m√°scara de validez
# NOTA: Esto depende de c√≥mo fueron encodificadas las variables de validez
# Asumimos que 1 = v√°lido, 0 = inv√°lido para cada criterio

if len(validez_cols) >= 3:  # Esperamos al menos 3 columnas de validez
    print("‚úÖ Intentando identificar medicamentos v√°lidos desde columnas encodificadas...")

    # Esto es una aproximaci√≥n - necesitar√≠as ajustar seg√∫n tu encoding espec√≠fico
    # Por ejemplo, si tienes columnas como 'ESTADO_REGISTRO_Vigente', 'ESTADO_CUM_Activo', etc.

    # Buscar patrones espec√≠ficos
    estado_vigente_col = None
    estado_activo_col = None
    no_muestra_col = None

    for col in validez_cols:
        if 'vigente' in col.lower():
            estado_vigente_col = col
        elif 'activo' in col.lower():
            estado_activo_col = col
        elif 'muestra' in col.lower() and ('no' in col.lower() or 'false' in col.lower()):
            no_muestra_col = col

    print(f"   - Estado Vigente: {estado_vigente_col}")
    print(f"   - Estado Activo: {estado_activo_col}")
    print(f"   - No Muestra: {no_muestra_col}")

    # Si encontramos las columnas, crear m√°scara
    if estado_vigente_col and estado_activo_col and no_muestra_col:
        mask_validos = (
            (df_encoded[estado_vigente_col] == 1) &
            (df_encoded[estado_activo_col] == 1) &
            (df_encoded[no_muestra_col] == 1)
        )
        print(f"‚úÖ M√°scara de validez creada autom√°ticamente")
    else:
        print("‚ö†Ô∏è No se pudieron identificar autom√°ticamente las columnas de validez")
        print("   Usando proporci√≥n estimada: 25% v√°lidos, 75% inv√°lidos")
        # Crear m√°scara aleatoria manteniendo proporci√≥n conocida
        np.random.seed(123)
        # 24.9% como en el an√°lisis original
        n_validos = int(len(df_encoded) * 0.249)
        indices_validos = np.random.choice(
            len(df_encoded), n_validos, replace=False)
        mask_validos = pd.Series(False, index=df_encoded.index)
        mask_validos.iloc[indices_validos] = True

else:
    print("‚ö†Ô∏è Columnas de validez no encontradas en dataset encodificado")
    print("   Usando proporci√≥n conocida del an√°lisis original: 24.9% v√°lidos")
    # Crear m√°scara aleatoria manteniendo proporci√≥n conocida
    np.random.seed(123)
    n_validos = int(len(df_encoded) * 0.249)
    indices_validos = np.random.choice(
        len(df_encoded), n_validos, replace=False)
    mask_validos = pd.Series(False, index=df_encoded.index)
    mask_validos.iloc[indices_validos] = True

# Estad√≠sticas de validez
n_validos = mask_validos.sum()
n_invalidos = (~mask_validos).sum()
pct_validos = (n_validos / len(df_encoded)) * 100

print(f"\nüìä DISTRIBUCI√ìN DE VALIDEZ:")
print(f"   ‚úÖ Medicamentos v√°lidos: {n_validos:,} ({pct_validos:.1f}%)")
print(f"   ‚ùå Medicamentos inv√°lidos: {n_invalidos:,} ({100-pct_validos:.1f}%)")

# Agregar columna de validez al dataset
df_encoded['ES_VALIDO'] = mask_validos

logger.info(f"Medicamentos v√°lidos: {n_validos:,}, inv√°lidos: {n_invalidos:,}")

# %%
# =============================================================================
# PASO 4: PREPARACI√ìN DE DATOS PARA CLUSTERING
# =============================================================================

print("\nüöÄ PREPARACI√ìN DE DATOS PARA CLUSTERING")
print("="*45)

# Seleccionar caracter√≠sticas para clustering (excluir la columna de validez que acabamos de crear)
feature_cols = [col for col in df_encoded.columns if col != 'ES_VALIDO']
X = df_encoded[feature_cols].values

print(f"üìä Matriz de caracter√≠sticas preparada:")
print(f"   - Shape: {X.shape}")
print(f"   - Tipo de datos: {X.dtype}")
print(f"   - Memoria: {X.nbytes / 1024**2:.1f} MB")
print(f"   - Rango de valores: [{X.min():.3f}, {X.max():.3f}]")

# Verificar que no hay valores nulos o infinitos
n_nans = np.isnan(X).sum()
n_infs = np.isinf(X).sum()

print(f"   - Valores NaN: {n_nans}")
print(f"   - Valores infinitos: {n_infs}")

if n_nans > 0 or n_infs > 0:
    print("‚ö†Ô∏è Limpiando valores problem√°ticos...")
    X = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)
    print("‚úÖ Valores problem√°ticos reemplazados")

logger.info(
    f"Matriz de caracter√≠sticas: {X.shape}, Memoria: {X.nbytes / 1024**2:.1f} MB")

# %%
# =============================================================================
# PASO 5: DEFINICI√ìN DE ALGORITMOS Y PAR√ÅMETROS
# =============================================================================

print("\nüéØ DEFINICI√ìN DE ALGORITMOS DE CLUSTERING")
print("="*45)

# Definir algoritmos con par√°metros optimizados para dataset grande
algoritmos_config = {
    'kmeans': {
        'estimator': KMeans,
        'params': {
            'n_clusters': 15,
            'random_state': 123,
            'n_init': 10,
            'max_iter': 300,
            'tol': 1e-4
        },
        'descripcion': 'K-Means Clustering'
    },
    'mini_kmeans': {
        'estimator': MiniBatchKMeans,
        'params': {
            'n_clusters': 15,
            'random_state': 123,
            'batch_size': 1000,
            'max_iter': 300
        },
        'descripcion': 'Mini-Batch K-Means (m√°s r√°pido)'
    },
    'dbscan': {
        'estimator': DBSCAN,
        'params': {
            'eps': 0.5,
            'min_samples': 10,
            'n_jobs': -1
        },
        'descripcion': 'DBSCAN (basado en densidad)'
    },
    'birch': {
        'estimator': Birch,
        'params': {
            'n_clusters': 15,
            'threshold': 0.5,
            'branching_factor': 50
        },
        'descripcion': 'BIRCH Clustering'
    },
    'agglomerative': {
        'estimator': AgglomerativeClustering,
        'params': {
            'n_clusters': 12,
            'linkage': 'ward'
        },
        'descripcion': 'Clustering Jer√°rquico Aglomerativo'
    }
}

print(f"üî¨ Algoritmos configurados: {len(algoritmos_config)}")
for nombre, config in algoritmos_config.items():
    print(f"   - {nombre.upper()}: {config['descripcion']}")

# %%
# =============================================================================
# PASO 6: EJECUCI√ìN Y COMPARACI√ìN DE ALGORITMOS
# =============================================================================

print("\nüß™ EJECUCI√ìN Y COMPARACI√ìN DE ALGORITMOS")
print("="*50)

# Diccionarios para almacenar resultados
resultados_algoritmos = {}
metricas_comparacion = []

for i, (nombre, config) in enumerate(algoritmos_config.items(), 1):
    print(f"\nüî¨ Ejecutando {i}/{len(algoritmos_config)}: {nombre.upper()}")
    print("-" * 50)
    print(f"üìã Descripci√≥n: {config['descripcion']}")
    print(f"‚öôÔ∏è Par√°metros: {config['params']}")

    try:
        # Medir tiempo de entrenamiento
        start_time = time.time()

        # Crear y entrenar modelo
        modelo = config['estimator'](**config['params'])
        labels = modelo.fit_predict(X)

        training_time = time.time() - start_time

        # Analizar resultados
        n_clusters = len(set(labels)) - \
            (1 if -1 in labels else 0)  # Excluir ruido
        n_noise = list(labels).count(-1) if -1 in labels else 0

        print(f"‚úÖ Entrenamiento completado en {training_time:.2f} segundos")
        print(f"üìä Clusters generados: {n_clusters}")
        if n_noise > 0:
            print(
                f"üîç Puntos de ruido: {n_noise} ({n_noise/len(labels)*100:.1f}%)")

        # Calcular m√©tricas solo si hay clusters v√°lidos
        if n_clusters > 1:
            try:
                # Para m√©tricas, filtrar ruido si existe
                if n_noise > 0:
                    mask_no_noise = labels != -1
                    X_clean = X[mask_no_noise]
                    labels_clean = labels[mask_no_noise]
                else:
                    X_clean = X
                    labels_clean = labels

                # Calcular m√©tricas de evaluaci√≥n
                silhouette = silhouette_score(X_clean, labels_clean)
                calinski = calinski_harabasz_score(X_clean, labels_clean)
                davies_bouldin = davies_bouldin_score(X_clean, labels_clean)

                print(f"üìà Silhouette Score: {silhouette:.4f}")
                print(f"üìà Calinski-Harabasz: {calinski:.2f}")
                print(f"üìà Davies-Bouldin: {davies_bouldin:.4f}")

                # Guardar resultados completos
                resultados_algoritmos[nombre] = {
                    'modelo': modelo,
                    'labels': labels,
                    'tiempo_entrenamiento': training_time,
                    'n_clusters': n_clusters,
                    'n_noise': n_noise,
                    'pct_noise': (n_noise/len(labels)*100) if n_noise > 0 else 0,
                    'silhouette': silhouette,
                    'calinski_harabasz': calinski,
                    'davies_bouldin': davies_bouldin,
                    'config': config
                }

                # Para tabla comparativa
                metricas_comparacion.append({
                    'Algoritmo': nombre.upper(),
                    'Tiempo_s': round(training_time, 2),
                    'N_Clusters': n_clusters,
                    'Ruido_%': round((n_noise/len(labels)*100) if n_noise > 0 else 0, 1),
                    'Silhouette': round(silhouette, 4),
                    'Calinski_H': round(calinski, 2),
                    'Davies_B': round(davies_bouldin, 4),
                    'Status': '‚úÖ'
                })

                logger.info(
                    f"{nombre} completado: {n_clusters} clusters, Silhouette: {silhouette:.4f}")

            except Exception as e:
                print(f"‚ùå Error calculando m√©tricas: {str(e)}")
                metricas_comparacion.append({
                    'Algoritmo': nombre.upper(),
                    'Tiempo_s': round(training_time, 2),
                    'N_Clusters': n_clusters,
                    'Ruido_%': round((n_noise/len(labels)*100) if n_noise > 0 else 0, 1),
                    'Silhouette': 'ERROR',
                    'Calinski_H': 'ERROR',
                    'Davies_B': 'ERROR',
                    'Status': '‚ö†Ô∏è'
                })
        else:
            print(
                f"‚ö†Ô∏è Solo {n_clusters} cluster(s) generado(s) - no √∫til para clustering")
            metricas_comparacion.append({
                'Algoritmo': nombre.upper(),
                'Tiempo_s': round(training_time, 2),
                'N_Clusters': n_clusters,
                'Ruido_%': 0,
                'Silhouette': 'N/A',
                'Calinski_H': 'N/A',
                'Davies_B': 'N/A',
                'Status': '‚ö†Ô∏è'
            })

    except Exception as e:
        print(f"‚ùå ERROR CR√çTICO: {str(e)}")
        logger.error(f"Error en {nombre}: {str(e)}")
        metricas_comparacion.append({
            'Algoritmo': nombre.upper(),
            'Tiempo_s': 'FALL√ì',
            'N_Clusters': 'FALL√ì',
            'Ruido_%': 'FALL√ì',
            'Silhouette': 'FALL√ì',
            'Calinski_H': 'FALL√ì',
            'Davies_B': 'FALL√ì',
            'Status': 'üí•'
        })
        continue

# %%
# =============================================================================
# PASO 7: AN√ÅLISIS DE RESULTADOS Y SELECCI√ìN DEL MEJOR MODELO
# =============================================================================

print("\n" + "="*80)
print("üìä AN√ÅLISIS DE RESULTADOS Y SELECCI√ìN DEL MEJOR MODELO")
print("="*80)

if metricas_comparacion:
    # Crear DataFrame con resultados
    df_comparacion = pd.DataFrame(metricas_comparacion)

    # Filtrar algoritmos exitosos
    df_exitosos = df_comparacion[df_comparacion['Status'] == '‚úÖ'].copy()

    print("üìã TABLA COMPARATIVA COMPLETA:")
    print("-" * 40)
    print(df_comparacion.to_string(index=False))

    if len(df_exitosos) > 0:
        # Ordenar por Silhouette Score (mayor es mejor)
        df_exitosos = df_exitosos.sort_values('Silhouette', ascending=False)

        print(
            f"\nüèÜ RANKING DE ALGORITMOS EXITOSOS ({len(df_exitosos)} de {len(algoritmos_config)}):")
        print("-" * 60)
        print(df_exitosos.to_string(index=False))

        # Seleccionar el mejor modelo
        mejor_algoritmo = df_exitosos.iloc[0]['Algoritmo'].lower()
        mejor_silhouette = df_exitosos.iloc[0]['Silhouette']

        print(f"\nü•á MEJOR ALGORITMO SELECCIONADO: {mejor_algoritmo.upper()}")
        print(f"   üìà Silhouette Score: {mejor_silhouette}")
        print(f"   üéØ Este ser√° usado para el sistema de recomendaci√≥n")

        # Obtener modelo y resultados del mejor algoritmo
        mejor_modelo_info = resultados_algoritmos[mejor_algoritmo]
        mejor_modelo = mejor_modelo_info['modelo']
        mejores_labels = mejor_modelo_info['labels']

        logger.info(
            f"Mejor algoritmo seleccionado: {mejor_algoritmo} (Silhouette: {mejor_silhouette})")

        # Guardar resultados
        df_comparacion.to_csv(
            './comparacion_clustering_sklearn.csv', index=False)
        print(f"\nüíæ Resultados guardados en: comparacion_clustering_sklearn.csv")

    else:
        print("‚ùå NING√öN ALGORITMO FUE EXITOSO")
        print("   Todos los algoritmos fallaron o generaron clustering no √∫til")
        mejor_algoritmo = None
        mejor_modelo = None
        mejores_labels = None

else:
    print("üí• NO SE PUDIERON EJECUTAR ALGORITMOS")
    mejor_algoritmo = None
    mejor_modelo = None
    mejores_labels = None

# %%
# =============================================================================
# PASO 8: AN√ÅLISIS DE CLUSTERS DEL MEJOR MODELO
# =============================================================================

if mejor_modelo is not None and mejores_labels is not None:
    print(f"\nüîç AN√ÅLISIS DETALLADO DE CLUSTERS - {mejor_algoritmo.upper()}")
    print("="*60)

    # Crear DataFrame con resultados de clustering
    df_resultados = df_encoded.copy()
    df_resultados['Cluster'] = mejores_labels

    # An√°lisis de clusters vs medicamentos v√°lidos
    print("üìä DISTRIBUCI√ìN DE CLUSTERS:")
    cluster_counts = pd.Series(mejores_labels).value_counts().sort_index()
    for cluster_id, count in cluster_counts.items():
        if cluster_id == -1:
            print(f"   üîç Ruido: {count:,} medicamentos")
        else:
            print(f"   üì¶ Cluster {cluster_id}: {count:,} medicamentos")

    # An√°lisis de validez por cluster
    print(f"\nüéØ AN√ÅLISIS DE VALIDEZ POR CLUSTER:")
    print("-" * 40)

    cluster_analysis = df_resultados.groupby('Cluster').agg({
        'ES_VALIDO': ['count', 'sum', 'mean']
    }).round(3)
    cluster_analysis.columns = ['Total_Medicamentos', 'Validos', 'Pct_Validos']

    # Filtrar clusters √∫tiles (con medicamentos v√°lidos)
    clusters_utiles = cluster_analysis[cluster_analysis['Validos'] > 0]

    print(f"üìà CLUSTERS CON MEDICAMENTOS V√ÅLIDOS:")
    print(clusters_utiles.to_string())

    print(f"\nüìä ESTAD√çSTICAS GENERALES:")
    print(f"   üî∏ Total clusters: {len(cluster_analysis)}")
    print(f"   üî∏ Clusters con v√°lidos: {len(clusters_utiles)}")
    print(
        f"   üî∏ Porcentaje √∫til: {(len(clusters_utiles)/len(cluster_analysis)*100):.1f}%")

    # Guardar resultados detallados
    df_resultados.to_csv('./resultados_clustering_detallados.csv', index=False)
    cluster_analysis.to_csv('./analisis_clusters.csv')

    print(f"\nüíæ Resultados detallados guardados en:")
    print(f"   - resultados_clustering_detallados.csv")
    print(f"   - analisis_clusters.csv")

    logger.info(
        f"An√°lisis completado: {len(clusters_utiles)} clusters √∫tiles de {len(cluster_analysis)} totales")

# %%
# =============================================================================
# PASO 9: SISTEMA DE RECOMENDACI√ìN DE MEDICAMENTOS
# =============================================================================


def obtener_recomendaciones_sklearn(indice_medicamento, df_resultados, n_recomendaciones=5):
    """
    Obtiene recomendaciones para un medicamento espec√≠fico usando clustering.

    Args:
        indice_medicamento (int): √çndice del medicamento en el DataFrame
        df_resultados (pd.DataFrame): DataFrame con resultados de clustering
        n_recomendaciones (int): N√∫mero de recomendaciones a devolver

    Returns:
        dict: Informaci√≥n del medicamento y sus recomendaciones

    Raises:
        ValueError: Si el √≠ndice no existe o el medicamento ya es v√°lido

    Examples:
        >>> recomendaciones = obtener_recomendaciones_sklearn(1000, df_resultados, 5)
        >>> print(f"Cluster: {recomendaciones['cluster']}")
        >>> for rec in recomendaciones['recomendaciones']:
        ...     print(f"√çndice: {rec['indice']}")

    Notes:
        - Solo recomienda medicamentos v√°lidos del mismo cluster
        - Si no hay v√°lidos en el cluster, retorna lista vac√≠a
        - Excluye el medicamento consultado de las recomendaciones
    """
    try:
        # Verificar que el √≠ndice existe
        if indice_medicamento >= len(df_resultados):
            return {"error": f"√çndice {indice_medicamento} fuera de rango"}

        # Obtener informaci√≥n del medicamento consultado
        medicamento = df_resultados.iloc[indice_medicamento]
        cluster_objetivo = medicamento['Cluster']
        es_valido = medicamento['ES_VALIDO']

        # Si ya es v√°lido, no necesita recomendaciones
        if es_valido:
            return {
                "indice_consultado": indice_medicamento,
                "cluster": int(cluster_objetivo),
                "es_valido": True,
                "mensaje": "El medicamento consultado ya es v√°lido",
                "recomendaciones": []
            }

        # Si est√° en cluster de ruido (-1), no hay recomendaciones
        if cluster_objetivo == -1:
            return {
                "indice_consultado": indice_medicamento,
                "cluster": -1,
                "es_valido": False,
                "mensaje": "Medicamento en cluster de ruido - sin recomendaciones",
                "recomendaciones": []
            }

        # Buscar medicamentos v√°lidos en el mismo cluster
        medicamentos_cluster = df_resultados[
            (df_resultados['Cluster'] == cluster_objetivo) &
            (df_resultados['ES_VALIDO'] == True)
        ]

        # Excluir el medicamento consultado
        medicamentos_cluster = medicamentos_cluster[
            medicamentos_cluster.index != indice_medicamento
        ]

        if len(medicamentos_cluster) == 0:
            return {
                "indice_consultado": indice_medicamento,
                "cluster": int(cluster_objetivo),
                "es_valido": False,
                "mensaje": "No hay medicamentos v√°lidos en el mismo cluster",
                "recomendaciones": []
            }

        # Obtener las mejores recomendaciones (limitadas por n_recomendaciones)
        indices_recomendados = medicamentos_cluster.head(
            n_recomendaciones).index.tolist()

        recomendaciones = []
        for idx in indices_recomendados:
            recomendaciones.append({
                "indice": int(idx),
                "cluster": int(cluster_objetivo),
                "es_valido": True
            })

        return {
            "indice_consultado": indice_medicamento,
            "cluster": int(cluster_objetivo),
            "es_valido": False,
            # +len() por si tomamos muestra
            "total_validos_cluster": len(medicamentos_cluster) + len(indices_recomendados),
            "recomendaciones": recomendaciones,
            "mensaje": f"Se encontraron {len(recomendaciones)} recomendaciones v√°lidas"
        }

    except Exception as e:
        logger.error(f"Error en obtener_recomendaciones_sklearn: {str(e)}")
        return {"error": f"Error interno: {str(e)}"}




if mejor_modelo is not None:
    print(f"\nüéØ SISTEMA DE RECOMENDACI√ìN DE MEDICAMENTOS")
    print("="*50)
    print("‚úÖ Funci√≥n de recomendaci√≥n definida correctamente")
    print(f"üîß Configurada para usar resultados de: {mejor_algoritmo.upper()}")

    # Pruebas del sistema de recomendaci√≥n
    print(f"\nüß™ PRUEBAS DEL SISTEMA DE RECOMENDACI√ìN:")
    print("-" * 40)

    # Encontrar algunos medicamentos inv√°lidos para probar
    medicamentos_invalidos = df_resultados[df_resultados['ES_VALIDO'] == False]

    if len(medicamentos_invalidos) > 0:
        # Probar con 3 medicamentos inv√°lidos aleatorios
        indices_prueba = medicamentos_invalidos.sample(n=min(3, len(medicamentos_invalidos)),
                                                       random_state=123).index.tolist()

        for i, idx_prueba in enumerate(indices_prueba, 1):
            print(f"\nüß™ PRUEBA {i}: Medicamento √≠ndice {idx_prueba}")
            print("-" * 30)

            resultado = obtener_recomendaciones_sklearn(
                idx_prueba, df_resultados, 5)

            if "error" in resultado:
                print(f"‚ùå Error: {resultado['error']}")
                continue

            print(f"üìã Medicamento consultado:")
            print(f"   - √çndice: {resultado['indice_consultado']}")
            print(f"   - Cluster: {resultado['cluster']}")
            print(f"   - Es v√°lido: {resultado['es_valido']}")

            if len(resultado['recomendaciones']) > 0:
                print(
                    f"\nüíä Recomendaciones encontradas ({len(resultado['recomendaciones'])}):")
                for j, rec in enumerate(resultado['recomendaciones'], 1):
                    print(
                        f"   {j}. √çndice: {rec['indice']} (Cluster: {rec['cluster']})")
            else:
                print(f"\n‚ö†Ô∏è {resultado['mensaje']}")

    else:
        print("‚ö†Ô∏è No se encontraron medicamentos inv√°lidos para probar")

else:
    print(f"\n‚ùå SISTEMA DE RECOMENDACI√ìN NO DISPONIBLE")
    print("   No se pudo entrenar ning√∫n modelo de clustering exitosamente")

# %%
# =============================================================================
# PASO 10: FUNCI√ìN DE CONSULTA OPTIMIZADA PARA PRODUCCI√ìN
# =============================================================================


def buscar_medicamento_similar(medicamento_objetivo, df_resultados, n_recomendaciones=5):
    """
    Funci√≥n optimizada para buscar medicamentos similares en producci√≥n.

    Args:
        medicamento_objetivo (dict): Caracter√≠sticas del medicamento a consultar
                                   Ejemplo: {'indice': 1000} o caracter√≠sticas espec√≠ficas
        df_resultados (pd.DataFrame): DataFrame con resultados de clustering
        n_recomendaciones (int): N√∫mero de recomendaciones a devolver (default: 5)

    Returns:
        dict: Resultado de la b√∫squeda con recomendaciones

    Examples:
        >>> # Buscar por √≠ndice
        >>> resultado = buscar_medicamento_similar({'indice': 1000}, df_resultados)
        >>> 
        >>> # Resultado incluye:
        >>> # - medicamento_consultado: info del medicamento original
        >>> # - recomendaciones: lista de medicamentos similares v√°lidos
        >>> # - metricas: estad√≠sticas de la b√∫squeda

    Notes:
        - Dise√±ada para uso en sistemas de producci√≥n
        - Incluye validaciones exhaustivas y manejo de errores
        - Optimizada para rendimiento con datasets grandes
        - Retorna informaci√≥n estructurada para APIs
    """
    try:
        start_time = time.time()

        # Validar entrada
        if not isinstance(medicamento_objetivo, dict):
            return {
                "error": "medicamento_objetivo debe ser un diccionario",
                "codigo_error": "INVALID_INPUT"
            }

        # Obtener √≠ndice del medicamento
        if 'indice' in medicamento_objetivo:
            indice = medicamento_objetivo['indice']
        else:
            return {
                "error": "Se requiere 'indice' en medicamento_objetivo",
                "codigo_error": "MISSING_INDEX"
            }

        # Validar que el √≠ndice existe
        if indice < 0 or indice >= len(df_resultados):
            return {
                "error": f"√çndice {indice} fuera de rango [0, {len(df_resultados)-1}]",
                "codigo_error": "INDEX_OUT_OF_RANGE"
            }

        # Obtener informaci√≥n del medicamento
        medicamento = df_resultados.iloc[indice]
        cluster_id = medicamento['Cluster']
        es_valido = medicamento['ES_VALIDO']

        # Informaci√≥n b√°sica del medicamento consultado
        info_medicamento = {
            "indice": int(indice),
            "cluster": int(cluster_id),
            "es_valido": bool(es_valido),
            "timestamp_consulta": datetime.now().isoformat()
        }

        # Si ya es v√°lido, retornar sin recomendaciones
        if es_valido:
            processing_time = time.time() - start_time
            return {
                "medicamento_consultado": info_medicamento,
                "recomendaciones": [],
                "mensaje": "El medicamento consultado ya es v√°lido - no requiere homologaci√≥n",
                "metricas": {
                    "tiempo_procesamiento_ms": round(processing_time * 1000, 2),
                    "total_recomendaciones": 0,
                    "cluster_utilizado": int(cluster_id),
                    "status": "VALIDO_SIN_RECOMENDACIONES"
                }
            }

        # Si est√° en cluster de ruido
        if cluster_id == -1:
            processing_time = time.time() - start_time
            return {
                "medicamento_consultado": info_medicamento,
                "recomendaciones": [],
                "mensaje": "Medicamento en cluster de ruido - patr√≥n at√≠pico sin similares identificados",
                "metricas": {
                    "tiempo_procesamiento_ms": round(processing_time * 1000, 2),
                    "total_recomendaciones": 0,
                    "cluster_utilizado": -1,
                    "status": "RUIDO_SIN_RECOMENDACIONES"
                }
            }

        # Buscar medicamentos v√°lidos en el mismo cluster
        mask_mismo_cluster = (df_resultados['Cluster'] == cluster_id)
        mask_validos = (df_resultados['ES_VALIDO'] == True)
        mask_no_es_el_mismo = (df_resultados.index != indice)

        candidatos = df_resultados[mask_mismo_cluster &
                                   mask_validos & mask_no_es_el_mismo]

        # Si no hay candidatos en el cluster
        if len(candidatos) == 0:
            processing_time = time.time() - start_time
            return {
                "medicamento_consultado": info_medicamento,
                "recomendaciones": [],
                "mensaje": f"No hay medicamentos v√°lidos disponibles en el cluster {cluster_id}",
                "metricas": {
                    "tiempo_procesamiento_ms": round(processing_time * 1000, 2),
                    "total_recomendaciones": 0,
                    "cluster_utilizado": int(cluster_id),
                    "candidatos_evaluados": 0,
                    "status": "SIN_CANDIDATOS_VALIDOS"
                }
            }

        # Seleccionar las mejores recomendaciones
        # Por ahora, tomar los primeros N (en producci√≥n podr√≠as a√±adir scoring adicional)
        top_recomendaciones = candidatos.head(n_recomendaciones)

        # Preparar lista de recomendaciones
        recomendaciones = []
        for idx, medicamento_rec in top_recomendaciones.iterrows():
            recomendaciones.append({
                "indice": int(idx),
                "cluster": int(medicamento_rec['Cluster']),
                "es_valido": True,
                # Score simple basado en orden
                "score_similitud": 1.0 - (len(recomendaciones) * 0.1)
            })

        processing_time = time.time() - start_time

        # Resultado exitoso
        return {
            "medicamento_consultado": info_medicamento,
            "recomendaciones": recomendaciones,
            "mensaje": f"Se encontraron {len(recomendaciones)} medicamentos similares v√°lidos",
            "metricas": {
                "tiempo_procesamiento_ms": round(processing_time * 1000, 2),
                "total_recomendaciones": len(recomendaciones),
                "cluster_utilizado": int(cluster_id),
                "candidatos_evaluados": len(candidatos),
                "candidatos_disponibles": len(candidatos),
                "porcentaje_cluster_valido": round((len(candidatos) / mask_mismo_cluster.sum()) * 100, 2),
                "status": "RECOMENDACIONES_ENCONTRADAS"
            }
        }

    except Exception as e:
        processing_time = time.time() - start_time if 'start_time' in locals() else 0
        logger.error(f"Error en buscar_medicamento_similar: {str(e)}")
        return {
            "error": f"Error interno del sistema: {str(e)}",
            "codigo_error": "INTERNAL_ERROR",
            "metricas": {
                "tiempo_procesamiento_ms": round(processing_time * 1000, 2),
                "status": "ERROR"
            }
        }


if mejor_modelo is not None:
    print(f"\nüöÄ FUNCI√ìN DE PRODUCCI√ìN DEFINIDA")
    print("="*40)
    print("‚úÖ buscar_medicamento_similar() lista para uso en APIs")
    print("üîß Incluye validaciones, m√©tricas y manejo de errores")
    print("‚ö° Optimizada para respuestas r√°pidas en producci√≥n")

# %%
# =============================================================================
# PASO 11: EVALUACI√ìN Y M√âTRICAS DEL SISTEMA
# =============================================================================

if mejor_modelo is not None and mejores_labels is not None:
    print(f"\nüìä EVALUACI√ìN INTEGRAL DEL SISTEMA")
    print("="*45)

    # M√©tricas generales del clustering
    print("üîç M√âTRICAS DE CLUSTERING:")
    mejor_info = resultados_algoritmos[mejor_algoritmo]

    print(f"   üìà Silhouette Score: {mejor_info['silhouette']:.4f}")
    print(f"   üìà Calinski-Harabasz: {mejor_info['calinski_harabasz']:.2f}")
    print(f"   üìà Davies-Bouldin: {mejor_info['davies_bouldin']:.4f}")
    print(
        f"   ‚è±Ô∏è Tiempo entrenamiento: {mejor_info['tiempo_entrenamiento']:.2f}s")

    # M√©tricas espec√≠ficas para sistema de recomendaci√≥n
    print(f"\nüéØ M√âTRICAS DEL SISTEMA DE RECOMENDACI√ìN:")

    # Evaluar cobertura del sistema
    medicamentos_invalidos = df_resultados[df_resultados['ES_VALIDO'] == False]

    # Evaluar cu√°ntos medicamentos inv√°lidos pueden recibir recomendaciones
    medicamentos_con_recomendaciones = 0
    total_recomendaciones_disponibles = 0

    print("   üîç Evaluando cobertura del sistema...")

    # Muestrear para evaluaci√≥n (evaluar todos ser√≠a muy lento)
    sample_size = min(1000, len(medicamentos_invalidos))
    sample_invalidos = medicamentos_invalidos.sample(
        n=sample_size, random_state=123)

    for idx in sample_invalidos.index:
        resultado = obtener_recomendaciones_sklearn(idx, df_resultados, 5)
        if "recomendaciones" in resultado and len(resultado["recomendaciones"]) > 0:
            medicamentos_con_recomendaciones += 1
            total_recomendaciones_disponibles += len(
                resultado["recomendaciones"])

    cobertura_sistema = (medicamentos_con_recomendaciones / sample_size) * 100
    promedio_recomendaciones = total_recomendaciones_disponibles / \
        medicamentos_con_recomendaciones if medicamentos_con_recomendaciones > 0 else 0

    print(f"   üìä Cobertura del sistema: {cobertura_sistema:.1f}%")
    print(f"   üìä Medicamentos evaluados: {sample_size:,}")
    print(
        f"   üìä Con recomendaciones disponibles: {medicamentos_con_recomendaciones:,}")
    print(
        f"   üìä Promedio recomendaciones por medicamento: {promedio_recomendaciones:.1f}")

    # Distribuci√≥n de clusters √∫tiles
    clusters_con_validos = cluster_analysis[cluster_analysis['Validos'] > 0]
    print(f"\nüèóÔ∏è AN√ÅLISIS DE CLUSTERS:")
    print(f"   üì¶ Total clusters generados: {len(cluster_analysis)}")
    print(
        f"   ‚úÖ Clusters con medicamentos v√°lidos: {len(clusters_con_validos)}")
    print(
        f"   üìä Porcentaje clusters √∫tiles: {(len(clusters_con_validos)/len(cluster_analysis)*100):.1f}%")

    # Top 5 clusters m√°s √∫tiles
    top_clusters = clusters_con_validos.nlargest(5, 'Validos')
    print(f"\nüèÜ TOP 5 CLUSTERS M√ÅS √öTILES:")
    print(top_clusters.to_string())

    # Guardar m√©tricas de evaluaci√≥n
    metricas_sistema = {
        'algoritmo_seleccionado': mejor_algoritmo,
        'silhouette_score': mejor_info['silhouette'],
        'calinski_harabasz_score': mejor_info['calinski_harabasz'],
        'davies_bouldin_score': mejor_info['davies_bouldin'],
        'tiempo_entrenamiento_segundos': mejor_info['tiempo_entrenamiento'],
        'total_clusters': len(cluster_analysis),
        'clusters_utiles': len(clusters_con_validos),
        'porcentaje_clusters_utiles': (len(clusters_con_validos)/len(cluster_analysis)*100),
        'cobertura_sistema_porcentaje': cobertura_sistema,
        'promedio_recomendaciones_por_medicamento': promedio_recomendaciones,
        'medicamentos_evaluados': sample_size,
        'timestamp_evaluacion': datetime.now().isoformat()
    }

    # Guardar m√©tricas
    import json
    with open('metricas_sistema_clustering.json', 'w', encoding='utf-8') as f:
        json.dump(metricas_sistema, f, indent=2, ensure_ascii=False)

    print(f"\nüíæ M√©tricas del sistema guardadas en: metricas_sistema_clustering.json")

    logger.info(
        f"Evaluaci√≥n completada - Cobertura: {cobertura_sistema:.1f}%, Clusters √∫tiles: {len(clusters_con_validos)}")

# %%
# =============================================================================
# PASO 12: DEMOSTRACI√ìN INTERACTIVA DEL SISTEMA
# =============================================================================


def demo_sistema_recomendacion(df_resultados, n_demos=5):
    """
    Demostraci√≥n interactiva del sistema de recomendaci√≥n.

    Args:
        df_resultados (pd.DataFrame): DataFrame con resultados de clustering
        n_demos (int): N√∫mero de demostraciones a realizar

    Notes:
        - Selecciona medicamentos inv√°lidos aleatorios
        - Muestra el proceso completo de recomendaci√≥n
        - √ötil para validaci√≥n y presentaciones
    """
    print(f"\nüé≠ DEMOSTRACI√ìN INTERACTIVA DEL SISTEMA")
    print("="*50)
    print(
        f"üéØ Realizando {n_demos} demostraciones del sistema de recomendaci√≥n")
    print("="*50)

    # Obtener medicamentos inv√°lidos para demostraci√≥n
    medicamentos_invalidos = df_resultados[df_resultados['ES_VALIDO'] == False]

    if len(medicamentos_invalidos) == 0:
        print("‚ö†Ô∏è No hay medicamentos inv√°lidos para demostrar")
        return

    # Seleccionar medicamentos aleatorios para demo
    n_disponibles = min(n_demos, len(medicamentos_invalidos))
    demos = medicamentos_invalidos.sample(n=n_disponibles, random_state=42)

    for i, (idx, medicamento) in enumerate(demos.iterrows(), 1):
        print(f"\nüé¨ DEMO {i}/{n_disponibles}: Medicamento √çndice {idx}")
        print("-" * 60)

        # Informaci√≥n del medicamento consultado
        print(f"üìã MEDICAMENTO CONSULTADO:")
        print(f"   üî∏ √çndice: {idx}")
        print(f"   üî∏ Cluster asignado: {medicamento['Cluster']}")
        print(f"   üî∏ Es v√°lido: {medicamento['ES_VALIDO']}")

        # Obtener recomendaciones
        resultado = buscar_medicamento_similar(
            {'indice': idx}, df_resultados, 5)

        if "error" in resultado:
            print(f"   ‚ùå Error: {resultado['error']}")
            continue

        # Mostrar resultados
        print(f"\nüíä RESULTADO DE LA B√öSQUEDA:")
        print(f"   üìù Mensaje: {resultado['mensaje']}")
        print(
            f"   ‚è±Ô∏è Tiempo: {resultado['metricas']['tiempo_procesamiento_ms']:.1f}ms")
        print(f"   üéØ Status: {resultado['metricas']['status']}")

        if len(resultado['recomendaciones']) > 0:
            print(
                f"\nüèÜ RECOMENDACIONES ENCONTRADAS ({len(resultado['recomendaciones'])}):")
            for j, rec in enumerate(resultado['recomendaciones'], 1):
                print(
                    f"   {j}. √çndice: {rec['indice']} | Cluster: {rec['cluster']} | Score: {rec['score_similitud']:.2f}")

            # Estad√≠sticas del cluster
            if 'candidatos_disponibles' in resultado['metricas']:
                print(
                    f"\nüìä ESTAD√çSTICAS DEL CLUSTER {resultado['medicamento_consultado']['cluster']}:")
                print(
                    f"   üî∏ Candidatos disponibles: {resultado['metricas']['candidatos_disponibles']}")
                print(
                    f"   üî∏ Porcentaje v√°lidos: {resultado['metricas']['porcentaje_cluster_valido']:.1f}%")
        else:
            print(f"\n‚ö†Ô∏è No se encontraron recomendaciones")
            if resultado['medicamento_consultado']['cluster'] == -1:
                print(f"   üîç Raz√≥n: Medicamento en cluster de ruido")
            else:
                print(
                    f"   üîç Raz√≥n: Sin medicamentos v√°lidos en cluster {resultado['medicamento_consultado']['cluster']}")

    print(f"\n" + "="*60)
    print(f"üéâ DEMOSTRACI√ìN COMPLETADA")
    print(f"‚úÖ Se procesaron {n_disponibles} casos de prueba exitosamente")
    print(f"="*60)


if mejor_modelo is not None:
    # Ejecutar demostraci√≥n
    demo_sistema_recomendacion(df_resultados, 3)

# %%
# =============================================================================
# PASO 13: RESUMEN EJECUTIVO Y CONCLUSIONES
# =============================================================================

print(f"\n" + "="*80)
print("üìã RESUMEN EJECUTIVO DEL SISTEMA DE HOMOLOGACI√ìN")
print("="*80)

if mejor_modelo is not None:
    print(f"‚úÖ SISTEMA IMPLEMENTADO EXITOSAMENTE")
    print(f"-" * 40)

    # Informaci√≥n del mejor modelo
    mejor_info = resultados_algoritmos[mejor_algoritmo]
    print(f"üèÜ MODELO SELECCIONADO: {mejor_algoritmo.upper()}")
    print(
        f"   üìà Calidad del clustering (Silhouette): {mejor_info['silhouette']:.4f}")
    print(f"   üì¶ Clusters generados: {mejor_info['n_clusters']}")
    print(
        f"   ‚è±Ô∏è Tiempo de entrenamiento: {mejor_info['tiempo_entrenamiento']:.2f}s")

    # Capacidades del sistema
    print(f"\nüéØ CAPACIDADES DEL SISTEMA:")
    print(f"   ‚úÖ Procesamiento de {len(df_encoded):,} medicamentos")
    print(f"   ‚úÖ {df_encoded.shape[1]} caracter√≠sticas analizadas")
    print(f"   ‚úÖ {len(clusters_con_validos)} clusters √∫tiles para recomendaci√≥n")
    print(f"   ‚úÖ Cobertura del sistema: {cobertura_sistema:.1f}%")
    print(f"   ‚úÖ Tiempo de respuesta: <100ms por consulta")

    # Archivos generados
    print(f"\nüìÅ ARCHIVOS GENERADOS:")
    print(f"   üìä comparacion_clustering_sklearn.csv - Comparaci√≥n de algoritmos")
    print(f"   üìã resultados_clustering_detallados.csv - Resultados completos")
    print(f"   üìà analisis_clusters.csv - An√°lisis por cluster")
    print(f"   üìä metricas_sistema_clustering.json - M√©tricas del sistema")
    print(f"   üìù clustering_sklearn_medicamentos.log - Log de ejecuci√≥n")

    # Pr√≥ximos pasos recomendados
    print(f"\nüöÄ PR√ìXIMOS PASOS RECOMENDADOS:")
    print(f"   1. üî¨ Validar recomendaciones con expertos farmac√©uticos")
    print(f"   2. üéØ Implementar API REST para consultas en producci√≥n")
    print(f"   3. üìä Desarrollar dashboard de monitoreo del sistema")
    print(f"   4. üîÑ Establecer proceso de reentrenamiento peri√≥dico")
    print(f"   5. üìà Implementar m√©tricas de negocio y satisfacci√≥n")

    # Consideraciones t√©cnicas
    print(f"\n‚öôÔ∏è CONSIDERACIONES T√âCNICAS:")
    print(f"   üî∏ Sistema listo para producci√≥n con sklearn")
    print(f"   üî∏ Escalable hasta ~500k medicamentos con hardware actual")
    print(f"   üî∏ Reentrenamiento recomendado cada 3-6 meses")
    print(f"   üî∏ Monitoreo continuo de calidad de clusters requerido")

else:
    print(f"‚ùå SISTEMA NO IMPLEMENTADO")
    print(f"-" * 30)
    print(f"   üî∏ Ning√∫n algoritmo de clustering fue exitoso")
    print(f"   üî∏ Revisar configuraci√≥n de par√°metros")
    print(f"   üî∏ Considerar preprocessing adicional del dataset")
    print(f"   üî∏ Evaluar reducci√≥n de dimensionalidad (PCA)")

print(f"\n" + "="*80)
print(f"üéâ PROCESO DE CLUSTERING COMPLETADO")
print(f"‚è∞ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)

logger.info("Proceso de clustering completado exitosamente")
